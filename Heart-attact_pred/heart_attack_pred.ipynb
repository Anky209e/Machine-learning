{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.read_csv('heart.csv')\n",
    "targets = inputs.pop('target')\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "targets = np.array(targets)\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_samples,no_features = inputs.shape\n",
    "no_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train,inputs_test,targets_train,targets_test = train_test_split(inputs, targets, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "inputs_train = StandardScaler().fit_transform(inputs_train)\n",
    "inputs_test = StandardScaler().fit_transform(inputs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = torch.from_numpy(inputs_train.astype(np.float32))\n",
    "inputs_test = torch.from_numpy(inputs_test.astype(np.float32))\n",
    "targets_train = torch.from_numpy(targets_train.astype(np.float32))\n",
    "targets_test = torch.from_numpy(targets_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([203, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train = targets_train.reshape(-1,1)\n",
    "targets_test = targets_test.reshape(-1,1)\n",
    "\n",
    "targets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(13,1)\n",
    "\n",
    "    def forward(self, targets_train ):\n",
    "        out = self.linear(targets_train)\n",
    "        targets_preds = torch.sigmoid(out)\n",
    "        return targets_preds\n",
    "\n",
    "model = LogisticRegression()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 20, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 30, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 40, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 50, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 60, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 70, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 80, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 90, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 100, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 110, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 120, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 130, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 140, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 150, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 160, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 170, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 180, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 190, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 200, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 210, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 220, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 230, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 240, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 250, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 260, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 270, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 280, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 290, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 300, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 310, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 320, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 330, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 340, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 350, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 360, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 370, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 380, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 390, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 400, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 410, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 420, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 430, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 440, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 450, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 460, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 470, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 480, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 490, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 500, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 510, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 520, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 530, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 540, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 550, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 560, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 570, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 580, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 590, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 600, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 610, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 620, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 630, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 640, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 650, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 660, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 670, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 680, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 690, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 700, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 710, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 720, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 730, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 740, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 750, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 760, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 770, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 780, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 790, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 800, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 810, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 820, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 830, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 840, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 850, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 860, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 870, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 880, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 890, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 900, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 910, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 920, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 930, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 940, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 950, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 960, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 970, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 980, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 990, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1000, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1010, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1020, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1030, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1040, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1050, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1060, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1070, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1080, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1090, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1100, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1110, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1120, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1130, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1140, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1150, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1160, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1170, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1180, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1190, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1200, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1210, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1220, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1230, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1240, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1250, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1260, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1270, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1280, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1290, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1300, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1310, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1320, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1330, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1340, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1350, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1360, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1370, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1380, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1390, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1400, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1410, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1420, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1430, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1440, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1450, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1460, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1470, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1480, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1490, Loss: 0.3405, ACC: 87.0\n",
      "Epoch: 1500, Loss: 0.3405, ACC: 87.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    targets_preds = model(inputs_train)\n",
    "    loss = loss_fn(targets_preds,targets_train)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    if(epoch+1)%10 == 0:\n",
    "        with torch.no_grad():\n",
    "            targets_preds = model(inputs_test)\n",
    "            targets_preds_cls = targets_preds.round()\n",
    "            acc = targets_preds_cls.eq(targets_test).sum() / float(inputs_test.shape[0])\n",
    "        \n",
    "            print(f'Epoch: {epoch+1}, Loss: {loss.item():.4f}, ACC: {acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'heart_attack_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def predict_heart_attack(age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal):\n",
    "#     inputs = [age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal]\n",
    "\n",
    "#     mean = [54.366336633663366, 0.6831683168316832, 0.966996699669967, 131.62376237623764, 246.26402640264027, \n",
    "#             0.1485148514851485, 0.528052805280528, 149.64686468646866, 0.32673267326732675, 1.0396039603960396,\n",
    "#             1.3993399339933994, 0.7293729372937293, 2.3135313531353137]\n",
    "#     std =  [9.067101638577872, 0.46524119304834577, 1.0303480250839463, 17.509178065734393, 51.74515101045713,\n",
    "#             0.3556096038825341, 0.5249911240963214, 22.86733258188924, 0.46901858543869346, 1.1591574732421364,\n",
    "#             0.6152084301256651, 1.0209175011165652, 0.6112653149988239]\n",
    "\n",
    "#     for i in range(len(mean)):\n",
    "#         inputs[i] = (inputs[i] - mean[i])/ std[i]\n",
    "\n",
    "#     inputs = torch.from_numpy(np.array(inputs).astype(np.float32))\n",
    "\n",
    "#     pre_model = LogisticRegression()\n",
    "#     pre_model.load_state_dict(torch.load('heart_attack_data.pth'))\n",
    "\n",
    "#     preds = pre_model(inputs)\n",
    "#     ans = \"None\"\n",
    "#     if preds.item() >= 0.5:\n",
    "#         ans = \"YES\"\n",
    "#         chance = round(preds.item()*100,2)\n",
    "#     else:\n",
    "#         ans = \"NO\"\n",
    "#         chance = round(100 - (preds.item()*100),2)\n",
    "    \n",
    "\n",
    "\n",
    "#     return ans , chance\n",
    "# values = [57,1,0,152,274,0,1,88,1,1.2,1,1,3]\n",
    "# print(predict_heart_attack(*values))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
