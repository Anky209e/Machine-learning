{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = FashionMNIST(root= 'data/', download=True, train=True,transform=ToTensor())\n",
    "test_dataset = FashionMNIST(root='data/', train=False,transform=ToTensor())\n",
    "len(train_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "train_loader = DataLoader(train_dataset,batch_size, shuffle=True,num_workers=2,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionNeural(nn.Module):\n",
    "    def __init__(self,in_size,hidden_size,num_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 32\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionNeural(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FashionNeural(input_size,hidden_size=hidden_size,num_classes=num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:[0]. Loss:0.32873809337615967\n",
      "Epochs:[1]. Loss:0.4329748749732971\n",
      "Epochs:[2]. Loss:0.4572157859802246\n",
      "Epochs:[3]. Loss:0.44975340366363525\n",
      "Epochs:[4]. Loss:0.5853168368339539\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epochs in range(num_epochs):\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        images = images.reshape(-1,28*28)\n",
    "        out = model(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epochs+1)%1== 0:\n",
    "        print(f'Epochs:[{epochs}]. Loss:{loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.77\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_samples = 0\n",
    "    n_correct = 0\n",
    "    for images,labels in test_loader:\n",
    "        images = images.reshape(-1,28*28)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (preds == labels).sum().item()\n",
    "    \n",
    "acc = (n_correct/n_samples)*100\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img,model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    xb = xb.reshape(-1,784)\n",
    "    yb = model(xb)\n",
    "    _,predicts = torch.max(yb, dim=1)\n",
    "    return predicts[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Sandal , Predicted: Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[323]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', train_dataset.classes[label], ', Predicted:', train_dataset.classes[predict(img, model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
